{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a9d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import jinja2\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from drain3 import TemplateMiner\n",
    "from drain3.template_miner_config import TemplateMinerConfig\n",
    "from drain3.file_persistence import FilePersistence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f1bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = kagglehub.dataset_download(\"boltzmannbrain/nab\")\n",
    "# print(\"Path to dataset files: \", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bd77cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a8485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.read_csv(r\"C:\\Users\\Martin James\\.cache\\kagglehub\\datasets\\boltzmannbrain\\nab\\versions\\1\\realAWSCloudwatch\\realAWSCloudwatch\\\")\n",
    "AWS_dir_path = Path(os.getenv(\"AWS_DIR_PATH\"))\n",
    "# all_AWS_paths = [os.path.join(AWS_dir_path, file) for file in os.listdir(AWS_dir_path) if file.endswith(\".csv\")]\n",
    "all_AWS_paths = [AWS_dir_path / file for file in os.listdir(str(AWS_dir_path)) if file.endswith(\".csv\")]\n",
    "\n",
    "# for my_path in all_AWS_paths:\n",
    "#     print(my_path.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479b38fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_name_gen = (x.name for x in all_AWS_paths)\n",
    "all_AWS_df_list = [pd.read_csv(my_path) for my_path in all_AWS_paths]\n",
    "\n",
    "for df in all_AWS_df_list:\n",
    "    std_scaler = StandardScaler()\n",
    "    rbst_scaler = RobustScaler()\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "    df['std_value'] = std_scaler.fit_transform(df[['value']]) # reminder that double brackets returns a df, not a series\n",
    "    # df['rbst_value'] = rbst_scaler.fit_transform(df[['value']])\n",
    "    # df.style.set_caption(next(AWS_name_gen, \"somethingWentWrong\"))\n",
    "    \n",
    "    display(df.tail(2).style.set_caption(next(AWS_name_gen, \"somethingWentWrong\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45f87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_df = all_AWS_df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261215cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iso(my_df, window=5, contamination=\"auto\"):\n",
    "    # window = 5\n",
    "    X = []\n",
    "\n",
    "    for i in range(len(my_df) - window):\n",
    "        X.append(my_df['std_value'].iloc[i:i+window].values)\n",
    "\n",
    "    X = np.array(X)\n",
    "\n",
    "    iso = IsolationForest(contamination=contamination, random_state=1)\n",
    "    y_pred = iso.fit_predict(X)\n",
    "\n",
    "    # align predictions with dataframe\n",
    "    my_df['anomaly_window'] = 0\n",
    "    my_df.loc[window-1:, 'anomaly_window'] = np.append((y_pred == -1).astype(int), 1) # fixing the minor misalignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff9e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_iso(inp_df, window=7)\n",
    "# inp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb744d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp_df.describe()\n",
    "inp_df[inp_df[\"anomaly_window\"] == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d42e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(inp_df['timestamp'], inp_df['std_value'], label='Standard-scaled Value', color='blue', zorder=1)\n",
    "\n",
    "# Optional: highlight anomalies if you have them\n",
    "anomalies = inp_df[inp_df['anomaly_window'] == 1]\n",
    "plt.scatter(anomalies['timestamp'], anomalies['std_value'], \n",
    "            color='red', label='Anomaly', marker='x', zorder=2)\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Standard-scaled value\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd5ff2",
   "metadata": {},
   "source": [
    "## MVAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850823ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d64ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "MVAD_csv_path = Path(os.getenv(\"MVAD_CSV_PATH\"))\n",
    "\n",
    "if merged_df == None:\n",
    "    merged_df = pd.read_csv(MVAD_csv_path)\n",
    "# merged_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81336d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfacf982",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"timestamp\"] = pd.to_datetime(merged_df[\"timestamp\"])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77983438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df[merged_df['anomaly']==nan].count()\n",
    "# merged_df[(merged_df['anomaly'].isna()) & (merged_df[\"identifier\"]==\"pc2\")]\n",
    "pc2_df = merged_df[(merged_df[\"identifier\"]==\"pc2\")]\n",
    "pc2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8249f10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_df = merged_df[merged_df[\"identifier\"] == \"pc1\"]\n",
    "pc1_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8052087e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scaler_pc1 = StandardScaler()\n",
    "scalable_columns = [\"cpu_temperature\", \"cpu_usage\", \"cpu_load\", \"memory_usage\", \"battery_level\", \"cpu_power\"]\n",
    "pc1_scaled = pd.DataFrame(std_scaler_pc1.fit_transform(pc1_df[scalable_columns]), columns=scalable_columns, index=pc1_df.index)\n",
    "pc1_scaled[\"timestamp\"] = pc1_df[\"timestamp\"]\n",
    "pc1_scaled[\"anomaly\"] = pc1_df[\"anomaly\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reordered_columns = [\"timestamp\"]\n",
    "reordered_columns.extend(scalable_columns)\n",
    "reordered_columns.extend([\"anomaly\"])\n",
    "# reordered_columns\n",
    "pc1_scaled = pc1_scaled[reordered_columns]\n",
    "# pc1_scaled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pc1_scaled.head())\n",
    "pc1_scaled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b5cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(pc1_scaled['timestamp'], pc1_scaled['cpu_temperature'], label='Standard-scaled Value of cpu_temperature', color='blue', zorder=1)\n",
    "\n",
    "# Optional: highlight anomalies if you have them\n",
    "# anomalies = inp_df[inp_df['anomaly_window'] == 1]\n",
    "# plt.scatter(anomalies['timestamp'], anomalies['std_value'], \n",
    "#             color='red', label='Anomaly', marker='x', zorder=2)\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Standard-scaled value\")\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a6db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_slice = pc1_df[pc1_df[\"timestamp\"] < pd.Timestamp(\"2024-12-02\")]\n",
    "# small_slice.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16eb446",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(small_slice['timestamp'], small_slice['cpu_temperature'], label='Value of cpu_temperature', color='red', zorder=1)\n",
    "\n",
    "# Optional: highlight anomalies if you have them\n",
    "# anomalies = inp_df[inp_df['anomaly_window'] == 1]\n",
    "# plt.scatter(anomalies['timestamp'], anomalies['std_value'], \n",
    "#             color='red', label='Anomaly', marker='x', zorder=2)\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Unscaled value\")\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789115b",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_slice_pc2 = pc2_df[pc2_df[\"timestamp\"] < pd.Timestamp(\"2024-11-30\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b9563",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(small_slice_pc2['timestamp'], small_slice_pc2['cpu_temperature'], label='Value of cpu_temperature', color='red', zorder=1)\n",
    "\n",
    "plt.xlabel(\"Timestamp\")\n",
    "plt.ylabel(\"Unscaled value\")\n",
    "# plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341e00e2",
   "metadata": {},
   "source": [
    "## After clarification of input data, log-parsing attempt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecaf875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "log_pattern = re.compile(r'^(?P<proc>\\S+)\\[(?P<pid>\\d+)\\]:\\s+(?P<rest>.*)$') # (?P<ourCustomName>...) is a way in python \n",
    "                                                                         # regex to get named capturing groups  \n",
    "\n",
    "config = TemplateMinerConfig()\n",
    "persistence = FilePersistence(\"drain3_state.bin\")\n",
    "template_miner = TemplateMiner(persistence, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f5712",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"exampleLog.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        # print(line.strip())\n",
    "        parts = line.split(maxsplit=4)  \n",
    "\n",
    "        date = f\"{parts[0]} {parts[1]}\"\n",
    "        time = parts[2]\n",
    "        node = parts[3]\n",
    "\n",
    "        # Step 2: regex for proc/pid/message\n",
    "\n",
    "        match = log_pattern.match(parts[4])\n",
    "\n",
    "        if match:\n",
    "            msg = match.group(\"rest\") \n",
    "            result = template_miner.add_log_message(msg)\n",
    "            print(\"Template:\", result[\"template_mined\"])\n",
    "            parsed = {\n",
    "                \"date\": date,\n",
    "                \"time\": time,\n",
    "                \"node\": node,\n",
    "                \"proc\": match.group(\"proc\"),\n",
    "                \"pid\": int(match.group(\"pid\")),\n",
    "                \"rest\": match.group(\"rest\")\n",
    "            }\n",
    "            print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68b28b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from itertools import islice\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ebe4efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_map = {\"TRACE\":0, \"DEBUG\":1, \"INFO\":2, \"WARN\":3, \"ERROR\":4, \"FATAL\":5}\n",
    "\n",
    "hdfs_drain3_config = TemplateMinerConfig()\n",
    "hdfs_drain3_persistence = FilePersistence(\"hdfs_drain3_state.bin\")\n",
    "hdfs_drain3_template_miner = TemplateMiner(hdfs_drain3_persistence, hdfs_drain3_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3b726317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_line(line):\n",
    "    parts = line.split(maxsplit=5)  \n",
    "    date_time = f\"{parts[0]} {parts[1]}\"\n",
    "    thread = parts[2]\n",
    "    level = parts[3]\n",
    "    log_origin = parts[4][:-1]\n",
    "    message = parts[5].strip()\n",
    "\n",
    "    template_obj = hdfs_drain3_template_miner.add_log_message(message)\n",
    "\n",
    "    parsed = {\n",
    "        \"date_time\": date_time,\n",
    "        \"thread\": thread,\n",
    "        \"level\": level,\n",
    "        \"log_origin\": log_origin,\n",
    "        \"message\": message,\n",
    "        \"template\": template_obj['template_mined'],\n",
    "        \"template_id\": template_obj['cluster_id']\n",
    "    }\n",
    "    # print(parsed)\n",
    "    return parsed\n",
    "\n",
    "def chunk_and_read(chunk_size = 1000):\n",
    "    with open(os.getenv(\"BIG_LOG_PATH\"), \"r\") as f:\n",
    "        while True:\n",
    "            lines = list(islice(f, chunk_size))\n",
    "            if not lines:\n",
    "                break\n",
    "            yield lines\n",
    "\n",
    "def process_in_lines(limiter=50):\n",
    "    i=0\n",
    "    with open(os.getenv(\"BIG_LOG_PATH\"), \"r\") as f:\n",
    "        for line in f:\n",
    "            if i == limiter:\n",
    "                break\n",
    "            print(line, end=\"\")\n",
    "            print(preprocess_line(line), end=\"\\n\\n\")\n",
    "            i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31f776e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "081109 203518 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106 dest: /10.250.19.102:50010\n",
      "{'date_time': '081109 203518', 'thread': '143', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106 dest: /10.250.19.102:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203518 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar. blk_-1608999687919862906\n",
      "{'date_time': '081109 203518', 'thread': '35', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar. blk_-1608999687919862906', 'template': 'BLOCK* NameSystem.allocateBlock: <*> <*>', 'template_id': 2}\n",
      "\n",
      "081109 203519 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\n",
      "{'date_time': '081109 203519', 'thread': '143', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203519 145 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.14.224:42420 dest: /10.250.14.224:50010\n",
      "{'date_time': '081109 203519', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-1608999687919862906 src: /10.250.14.224:42420 dest: /10.250.14.224:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203519 145 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-1608999687919862906 terminating\n",
      "{'date_time': '081109 203519', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 1 for block blk_-1608999687919862906 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203519 145 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-1608999687919862906 terminating\n",
      "{'date_time': '081109 203519', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 2 for block blk_-1608999687919862906 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203519 145 INFO dfs.DataNode$PacketResponder: Received block blk_-1608999687919862906 of size 91178 from /10.250.10.6\n",
      "{'date_time': '081109 203519', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_-1608999687919862906 of size 91178 from /10.250.10.6', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203519 145 INFO dfs.DataNode$PacketResponder: Received block blk_-1608999687919862906 of size 91178 from /10.250.19.102\n",
      "{'date_time': '081109 203519', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_-1608999687919862906 of size 91178 from /10.250.19.102', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203519 147 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-1608999687919862906 terminating\n",
      "{'date_time': '081109 203519', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 0 for block blk_-1608999687919862906 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203519 147 INFO dfs.DataNode$PacketResponder: Received block blk_-1608999687919862906 of size 91178 from /10.250.14.224\n",
      "{'date_time': '081109 203519', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_-1608999687919862906 of size 91178 from /10.250.14.224', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203519 29 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.10.6:50010 is added to blk_-1608999687919862906 size 91178\n",
      "{'date_time': '081109 203519', 'thread': '29', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.10.6:50010 is added to blk_-1608999687919862906 size 91178', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n",
      "081109 203519 30 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.111.209:50010 is added to blk_-1608999687919862906 size 91178\n",
      "{'date_time': '081109 203519', 'thread': '30', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.111.209:50010 is added to blk_-1608999687919862906 size 91178', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n",
      "081109 203519 31 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.14.224:50010 is added to blk_-1608999687919862906 size 91178\n",
      "{'date_time': '081109 203519', 'thread': '31', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.250.14.224:50010 is added to blk_-1608999687919862906 size 91178', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n",
      "081109 203520 142 INFO dfs.DataNode$DataXceiver: Receiving block blk_7503483334202473044 src: /10.251.215.16:55695 dest: /10.251.215.16:50010\n",
      "{'date_time': '081109 203520', 'thread': '142', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_7503483334202473044 src: /10.251.215.16:55695 dest: /10.251.215.16:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203520 145 INFO dfs.DataNode$DataXceiver: Receiving block blk_7503483334202473044 src: /10.250.19.102:34232 dest: /10.250.19.102:50010\n",
      "{'date_time': '081109 203520', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_7503483334202473044 src: /10.250.19.102:34232 dest: /10.250.19.102:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203520 26 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.split. blk_7503483334202473044\n",
      "{'date_time': '081109 203520', 'thread': '26', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.split. blk_7503483334202473044', 'template': 'BLOCK* NameSystem.allocateBlock: <*> <*>', 'template_id': 2}\n",
      "\n",
      "081109 203521 143 INFO dfs.DataNode$DataXceiver: Received block blk_-1608999687919862906 src: /10.251.215.16:52002 dest: /10.251.215.16:50010 of size 91178\n",
      "{'date_time': '081109 203521', 'thread': '143', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Received block blk_-1608999687919862906 src: /10.251.215.16:52002 dest: /10.251.215.16:50010 of size 91178', 'template': 'Received block blk_-1608999687919862906 src: <*> dest: <*> of size 91178', 'template_id': 6}\n",
      "\n",
      "081109 203521 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.251.215.16:52002 dest: /10.251.215.16:50010\n",
      "{'date_time': '081109 203521', 'thread': '143', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-1608999687919862906 src: /10.251.215.16:52002 dest: /10.251.215.16:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203521 144 INFO dfs.DataNode$DataXceiver: Receiving block blk_7503483334202473044 src: /10.251.71.16:51590 dest: /10.251.71.16:50010\n",
      "{'date_time': '081109 203521', 'thread': '144', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_7503483334202473044 src: /10.251.71.16:51590 dest: /10.251.71.16:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203521 145 INFO dfs.DataNode$DataXceiver: Receiving block blk_-3544583377289625738 src: /10.250.19.102:39325 dest: /10.250.19.102:50010\n",
      "{'date_time': '081109 203521', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-3544583377289625738 src: /10.250.19.102:39325 dest: /10.250.19.102:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203521 145 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_7503483334202473044 terminating\n",
      "{'date_time': '081109 203521', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 1 for block blk_7503483334202473044 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203521 145 INFO dfs.DataNode$PacketResponder: Received block blk_7503483334202473044 of size 233217 from /10.251.215.16\n",
      "{'date_time': '081109 203521', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_7503483334202473044 of size 233217 from /10.251.215.16', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203521 146 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_7503483334202473044 terminating\n",
      "{'date_time': '081109 203521', 'thread': '146', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 0 for block blk_7503483334202473044 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203521 146 INFO dfs.DataNode$PacketResponder: Received block blk_7503483334202473044 of size 233217 from /10.251.71.16\n",
      "{'date_time': '081109 203521', 'thread': '146', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_7503483334202473044 of size 233217 from /10.251.71.16', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203521 147 INFO dfs.DataNode$DataTransfer: 10.250.14.224:50010:Transmitted block blk_-1608999687919862906 to /10.251.215.16:50010\n",
      "{'date_time': '081109 203521', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataTransfer', 'message': '10.250.14.224:50010:Transmitted block blk_-1608999687919862906 to /10.251.215.16:50010', 'template': '10.250.14.224:50010:Transmitted block blk_-1608999687919862906 to /10.251.215.16:50010', 'template_id': 7}\n",
      "\n",
      "081109 203521 147 INFO dfs.DataNode$DataXceiver: Received block blk_-1608999687919862906 src: /10.250.14.224:35754 dest: /10.250.14.224:50010 of size 91178\n",
      "{'date_time': '081109 203521', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Received block blk_-1608999687919862906 src: /10.250.14.224:35754 dest: /10.250.14.224:50010 of size 91178', 'template': 'Received block blk_-1608999687919862906 src: <*> dest: <*> of size 91178', 'template_id': 6}\n",
      "\n",
      "081109 203521 147 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.14.224:35754 dest: /10.250.14.224:50010\n",
      "{'date_time': '081109 203521', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-1608999687919862906 src: /10.250.14.224:35754 dest: /10.250.14.224:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203521 148 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_7503483334202473044 terminating\n",
      "{'date_time': '081109 203521', 'thread': '148', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 2 for block blk_7503483334202473044 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203521 148 INFO dfs.DataNode$PacketResponder: Received block blk_7503483334202473044 of size 233217 from /10.250.19.102\n",
      "{'date_time': '081109 203521', 'thread': '148', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_7503483334202473044 of size 233217 from /10.250.19.102', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203521 19 INFO dfs.DataNode: 10.250.14.224:50010 Starting thread to transfer block blk_-1608999687919862906 to 10.251.215.16:50010, 10.251.71.193:50010\n",
      "{'date_time': '081109 203521', 'thread': '19', 'level': 'INFO', 'log_origin': 'dfs.DataNode', 'message': '10.250.14.224:50010 Starting thread to transfer block blk_-1608999687919862906 to 10.251.215.16:50010, 10.251.71.193:50010', 'template': '10.250.14.224:50010 Starting thread to transfer block blk_-1608999687919862906 to 10.251.215.16:50010, 10.251.71.193:50010', 'template_id': 8}\n",
      "\n",
      "081109 203521 19 INFO dfs.FSNamesystem: BLOCK* ask 10.250.14.224:50010 to replicate blk_-1608999687919862906 to datanode(s) 10.251.215.16:50010 10.251.71.193:50010\n",
      "{'date_time': '081109 203521', 'thread': '19', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* ask 10.250.14.224:50010 to replicate blk_-1608999687919862906 to datanode(s) 10.251.215.16:50010 10.251.71.193:50010', 'template': 'BLOCK* ask 10.250.14.224:50010 to replicate blk_-1608999687919862906 to datanode(s) 10.251.215.16:50010 10.251.71.193:50010', 'template_id': 9}\n",
      "\n",
      "081109 203521 27 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.106.10:50010 is added to blk_7503483334202473044 size 233217\n",
      "{'date_time': '081109 203521', 'thread': '27', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.106.10:50010 is added to blk_7503483334202473044 size 233217', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n",
      "081109 203521 29 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.xml. blk_-3544583377289625738\n",
      "{'date_time': '081109 203521', 'thread': '29', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.xml. blk_-3544583377289625738', 'template': 'BLOCK* NameSystem.allocateBlock: <*> <*>', 'template_id': 2}\n",
      "\n",
      "081109 203521 30 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.71.193:50010 is added to blk_-1608999687919862906 size 91178\n",
      "{'date_time': '081109 203521', 'thread': '30', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.71.193:50010 is added to blk_-1608999687919862906 size 91178', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n",
      "081109 203521 33 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.215.16:50010 is added to blk_7503483334202473044 size 233217\n",
      "{'date_time': '081109 203521', 'thread': '33', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.215.16:50010 is added to blk_7503483334202473044 size 233217', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n",
      "081109 203521 34 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.215.16:50010 is added to blk_-1608999687919862906 size 91178\n",
      "{'date_time': '081109 203521', 'thread': '34', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.215.16:50010 is added to blk_-1608999687919862906 size 91178', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n",
      "081109 203521 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.71.16:50010 is added to blk_7503483334202473044 size 233217\n",
      "{'date_time': '081109 203521', 'thread': '35', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.71.16:50010 is added to blk_7503483334202473044 size 233217', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n",
      "081109 203522 144 INFO dfs.DataNode$DataXceiver: Receiving block blk_-3544583377289625738 src: /10.251.197.226:60229 dest: /10.251.197.226:50010\n",
      "{'date_time': '081109 203522', 'thread': '144', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-3544583377289625738 src: /10.251.197.226:60229 dest: /10.251.197.226:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203522 145 INFO dfs.DataNode$DataXceiver: Receiving block blk_-3544583377289625738 src: /10.250.11.100:54800 dest: /10.250.11.100:50010\n",
      "{'date_time': '081109 203522', 'thread': '145', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-3544583377289625738 src: /10.250.11.100:54800 dest: /10.250.11.100:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203522 147 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-3544583377289625738 terminating\n",
      "{'date_time': '081109 203522', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 2 for block blk_-3544583377289625738 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203522 147 INFO dfs.DataNode$PacketResponder: Received block blk_-3544583377289625738 of size 11971 from /10.250.19.102\n",
      "{'date_time': '081109 203522', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_-3544583377289625738 of size 11971 from /10.250.19.102', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203523 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-9073992586687739851 src: /10.250.19.102:37673 dest: /10.250.19.102:50010\n",
      "{'date_time': '081109 203523', 'thread': '143', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': 'Receiving block blk_-9073992586687739851 src: /10.250.19.102:37673 dest: /10.250.19.102:50010', 'template': 'Receiving block <*> src: <*> dest: <*>', 'template_id': 1}\n",
      "\n",
      "081109 203523 146 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-3544583377289625738 terminating\n",
      "{'date_time': '081109 203523', 'thread': '146', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 1 for block blk_-3544583377289625738 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203523 146 INFO dfs.DataNode$PacketResponder: Received block blk_-3544583377289625738 of size 11971 from /10.251.197.226\n",
      "{'date_time': '081109 203523', 'thread': '146', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_-3544583377289625738 of size 11971 from /10.251.197.226', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203523 147 INFO dfs.DataNode$PacketResponder: PacketResponder 0 for block blk_-3544583377289625738 terminating\n",
      "{'date_time': '081109 203523', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'PacketResponder 0 for block blk_-3544583377289625738 terminating', 'template': 'PacketResponder <*> for block <*> terminating', 'template_id': 3}\n",
      "\n",
      "081109 203523 147 INFO dfs.DataNode$PacketResponder: Received block blk_-3544583377289625738 of size 11971 from /10.250.11.100\n",
      "{'date_time': '081109 203523', 'thread': '147', 'level': 'INFO', 'log_origin': 'dfs.DataNode$PacketResponder', 'message': 'Received block blk_-3544583377289625738 of size 11971 from /10.250.11.100', 'template': 'Received block <*> of size <*> from <*>', 'template_id': 4}\n",
      "\n",
      "081109 203523 148 INFO dfs.DataNode$DataXceiver: 10.250.11.100:50010 Served block blk_-3544583377289625738 to /10.250.19.102\n",
      "{'date_time': '081109 203523', 'thread': '148', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': '10.250.11.100:50010 Served block blk_-3544583377289625738 to /10.250.19.102', 'template': '<*> Served block <*> to /10.250.19.102', 'template_id': 10}\n",
      "\n",
      "081109 203523 149 INFO dfs.DataNode$DataXceiver: 10.251.111.209:50010 Served block blk_-1608999687919862906 to /10.250.19.102\n",
      "{'date_time': '081109 203523', 'thread': '149', 'level': 'INFO', 'log_origin': 'dfs.DataNode$DataXceiver', 'message': '10.251.111.209:50010 Served block blk_-1608999687919862906 to /10.250.19.102', 'template': '<*> Served block <*> to /10.250.19.102', 'template_id': 10}\n",
      "\n",
      "081109 203523 28 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /user/root/rand/_logs/history/ip-10-250-19-102.ec2.internal_1226291400491_job_200811092030_0001_conf.xml. blk_-9073992586687739851\n",
      "{'date_time': '081109 203523', 'thread': '28', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.allocateBlock: /user/root/rand/_logs/history/ip-10-250-19-102.ec2.internal_1226291400491_job_200811092030_0001_conf.xml. blk_-9073992586687739851', 'template': 'BLOCK* NameSystem.allocateBlock: <*> <*>', 'template_id': 2}\n",
      "\n",
      "081109 203523 29 INFO dfs.FSNamesystem: BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.39.179:50010 is added to blk_-3544583377289625738 size 11971\n",
      "{'date_time': '081109 203523', 'thread': '29', 'level': 'INFO', 'log_origin': 'dfs.FSNamesystem', 'message': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: 10.251.39.179:50010 is added to blk_-3544583377289625738 size 11971', 'template': 'BLOCK* NameSystem.addStoredBlock: blockMap updated: <*> is added to <*> size <*>', 'template_id': 5}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process_in_lines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94ae48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next steps\n",
    "\n",
    "\"\"\"\n",
    "Chunk by lines, \n",
    "save those as Dataframes and convert datetime, int, onehot encoded template ids, ordinal encoded levels, and int(thread)\n",
    "create sliding window features\n",
    "train model (IsoForest first, and then SVM and maybe LSTM autoencoder (keep 'pd.parquet's of dataframe before temporal)) batchwise\n",
    "set up process in case new template found, to quickly retrain/integrate\n",
    "Further automate this for reuse in multiple different log formats\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91aa595",
   "metadata": {},
   "source": [
    "### Spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15889d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
